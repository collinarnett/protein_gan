{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio.PDB import *\n",
    "import multiprocessing as mp\n",
    "import h5py\n",
    "import logging\n",
    "from math import floor\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biopython creates warnings for chains that are discontinuous. I recommend turning them off.\n",
    "import warnings\n",
    "from Bio import BiopythonWarning\n",
    "warnings.simplefilter('ignore', BiopythonWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='data_generation.log',level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Variables\n",
    "#----------------\n",
    "# Requires absolute path\n",
    "test_path = pathlib.Path(\"/home/collin/protein_gan/data/test/\")\n",
    "train_path = pathlib.Path(\"/home/collin/protein_gan/data/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_matrix(matrix, res):\n",
    "    if (len(matrix)>=res):\n",
    "        for n in range(1,int(floor(len(matrix)/res))):\n",
    "            # Creating RES x RES matrices by traversing the spine of input matrix\n",
    "            matrix_chunk = matrix[res*(n-1):res*n, res*(n-1):res*n]\n",
    "            yield matrix_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist_matrix(residues):\n",
    "    \"\"\"Returns a matrix of distances between residues of the same chain.\"\"\"\n",
    "    size = len(residues)\n",
    "    answer = np.zeros((size, size), np.float)\n",
    "    for row, residue_one in enumerate(residues):\n",
    "        for col, residue_two in enumerate(residues):\n",
    "            answer[row, col] = residue_one[\"CA\"] - residue_two[\"CA\"]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_maps(files):\n",
    "    \"\"\"\n",
    "    Generate specified resolution a-carbon maps given a input directory\n",
    "    \"\"\"\n",
    "    # Create A chain maps as matrices\n",
    "    parser = PDBParser()\n",
    "    io = PDBIO()\n",
    "    # Get the initial structure of the protein\n",
    "    try:    \n",
    "        structure = parser.get_structure('X', files)\n",
    "        for models in structure:\n",
    "            residues = Selection.unfold_entities(models['A'], 'R')\n",
    "            ca_residues = [residue for residue in residues if 'CA' in residue]\n",
    "            distance_matrix = calc_dist_matrix(ca_residues)\n",
    "            return (list(split_matrix(distance_matrix, 16)), \n",
    "                        list(split_matrix(distance_matrix, 64)), \n",
    "                        list(split_matrix(distance_matrix, 128)))\n",
    "    except ValueError as err:\n",
    "        logging.error(f'ValuError file :{files}, Error is:{err}')\n",
    "    except TypeError as err:\n",
    "        logging.error(f'TypeError file :{files}, Error is:{err}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(files, desc):\n",
    "    \"\"\"\n",
    "    Clean the generated maps using all cores in the process\n",
    "    \"\"\"\n",
    "    p = mp.Pool()\n",
    "    pdbs = [file for file in files.glob(\"*.pdb\")]\n",
    "    r = list(tqdm(p.imap(generate_maps, pdbs), total=len(pdbs), desc=desc))\n",
    "    p.close()\n",
    "    p.join()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_result(result):\n",
    "    test_len = [len(x) for x in result]\n",
    "    plt.hist(test_len)\n",
    "    plt.show()\n",
    "    plt.imshow(result[5], cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = main(test_path, \"test_sets\")\n",
    "test_16 = []\n",
    "test_64 = []\n",
    "test_128 = []\n",
    "for files in test_sets:\n",
    "    for matrix in files[0]:\n",
    "        test_16.append(matrix)\n",
    "    for matrix in files[1]:\n",
    "        test_64.append(matrix)\n",
    "    for matrix in files[2]:\n",
    "        test_128.append(matrix)\n",
    "with h5py.File('dataset.hdf5', 'w') as f:\n",
    "    f.create_dataset('test_16', data=test_16, compression=\"gzip\")\n",
    "    f.create_dataset('test_64', data=test_64, compression=\"gzip\")\n",
    "    f.create_dataset('test_128', data=test_128, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d4ef66a47a412abb4d31c30386af0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='train_sets', max=115850.0, style=ProgressStyle(descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sets = main(train_path, \"train_sets\")\n",
    "train_16 = []\n",
    "train_64 = []\n",
    "train_128 = []\n",
    "for files in train_sets:\n",
    "    for matrix in files[0]:\n",
    "        train_16.append(matrix)\n",
    "    for matrix in files[1]:\n",
    "        train_64.append(matrix)\n",
    "    for matrix in files[2]:\n",
    "        train_128.append(matrix)\n",
    "with h5py.File('dataset.hdf5', 'a') as f:\n",
    "    f.create_dataset('train_16', data=train_16, compression=\"gzip\")\n",
    "    f.create_dataset('train_64', data=train_64, compression=\"gzip\")\n",
    "    f.create_dataset('train_128', data=train_128, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
